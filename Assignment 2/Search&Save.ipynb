{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use this script to search through Twitter and save the data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "First, import required libraries. Two main libraries that we use here are *requests* and *urllib2*.\n",
    "We store the data in *json* format which makes the analysis easier.\n",
    "\n",
    "Second, we define some functions. Below, we introduce the functions:\n",
    "1. *pretty_print* is an auxiliary function which prints json files in an easily readable format.\n",
    "\n",
    "2. *get_token* sends a request to recieve the access token code.\n",
    "\n",
    "3. *acc_token* returns the access token in the correct format.\n",
    "\n",
    "4. *search_save* takes some keyword arguments, also the access token, searches through the right url, and saves the search results in json format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import urllib2\n",
    "import json\n",
    "import base64\n",
    "import pandas\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pretty_print(jsondata) :\n",
    "    print json.dumps(jsondata, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_token():\n",
    "    consumer_key = \"fQGKP2WVd3tuZtftBUVIBjDvg\"\n",
    "    consumer_secret = \"6eahgFefwaH7VRD89pXaNhyU5vMsX5Lgywy5cDvJC7CP0bFCLe\"\n",
    "    b64 = base64.b64encode(consumer_key+\":\"+consumer_secret)\n",
    "    headers = {'Authorization':' Basic '+b64 , 'Content-Type':'application/x-www-form-urlencoded;charset=UTF-8'}\n",
    "    r = requests.post(\"https://api.twitter.com/oauth2/token\", headers = headers , data = {'grant_type':'client_credentials'})\n",
    "    return r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def acc_token():\n",
    "    my_account=get_token()\n",
    "    json_acceptable_string = my_account.replace(\"'\", \"\\\"\")\n",
    "    d = json.loads(json_acceptable_string)\n",
    "    acc_token = ' Bearer '+str(d['access_token'])\n",
    "    return acc_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_search(kargs,access_token,output=False):\n",
    "    \n",
    "    results = requests.get(\"https://api.twitter.com/1.1/search/tweets.json\",headers = {'Authorization':access_token},params = kargs).json()\n",
    "\n",
    "    collected_tweets = results[\"statuses\"]\n",
    "    collected_meta_data = results[\"search_metadata\"]\n",
    "    while True :\n",
    "        try :\n",
    "            next_results = collected_meta_data[\"next_results\"]\n",
    "\n",
    "            kwargs = urllib2.urlparse.parse_qs(next_results[1:])\n",
    "\n",
    "\n",
    "            results =  requests.get(\"https://api.twitter.com/1.1/search/tweets.json\",headers = {'Authorization':access_token},params = kwargs).json()\n",
    "\n",
    "            collected_tweets += results[\"statuses\"]\n",
    "            collected_meta_data = results[\"search_metadata\"]\n",
    "        except :\n",
    "            break\n",
    "\n",
    "            \n",
    "            \n",
    "    while True:\n",
    "        try:\n",
    "            with open('./search/'+kargs['q'] + \".json\", 'w') as file_out :\n",
    "                json.dump(collected_tweets, file_out,indent=2)\n",
    "            path = './search/'+kargs['q'] + \".json\"\n",
    "            break\n",
    "        except IOError:\n",
    "            with open('./search/'+kargs['q'][:4] + \".json\", 'w') as file_out :\n",
    "                json.dump(collected_tweets, file_out,indent=2)\n",
    "            path = './search/'+kargs['q'][:4] + \".json\"\n",
    "            break\n",
    "            \n",
    "            \n",
    "            \n",
    "    with open(path, 'w') as file_out :\n",
    "            json.dump(collected_tweets, file_out,indent=2)\n",
    "    if output:\n",
    "        return collected_tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "access_token = acc_token()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we want to search tweets about Manchester United and Manchester City! We want to make sure that we cover all hashtags, with lower letters and upper letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "key_words_list_U = [\"#MUFC\", \"#mufc\", \"#Mufc\"]\n",
    "key_words_str_U = \" OR \".join(key_words_list)\n",
    "kargs_U = {'q':key_words_str,'lang':'en','count':100,'per_page':50}\n",
    "save_search(kargs_U,access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "key_words_list_C = [\"#MCFC\", \"#mcfc\", \"#Mcfc\"]\n",
    "key_words_str_C = \" OR \".join(key_words_list)\n",
    "kargs_C = {'q':key_words_str,'lang':'en','count':100,'per_page':100}\n",
    "save_search(kargs_C,access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "key_words_list_U = [\"MUFC :)\", \"mufc :)\", \"Mufc :)\", \"ManUtd :)\"]\n",
    "key_words_str_U = \" OR \".join(key_words_list_U)\n",
    "kargs_U = {'q':key_words_str_U,'count':100,'per_page':100}\n",
    "save_search(kargs_U,access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key_words_list_C = [\"MCFC :)\", \"mcfc :)\", \"Mcfc :)\", \"ManCity :)\"]\n",
    "key_words_str_C = \" OR \".join(key_words_list_C)\n",
    "kargs_C = {'q':key_words_str_C,'count':100,'per_page':100}\n",
    "save_search(kargs_C,access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
